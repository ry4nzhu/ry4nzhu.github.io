[{"authors":["admin"],"categories":null,"content":"My name is Ruiyang Zhu. I am a fifth-year Ph.D. student [ CV ] in Computer Science and Engineering at the University of Michigan, advised by Prof. Z. Morley Mao. My research interests broadly include computer systems and networks, with a focus on mobile networks and networked systems. My current research focus on cooperative perception on connected and autonomous vehicles.\nBefore the start of my Ph.D. journey, I received my bachelor degrees in Computer Engineering from Shanghai Jiao Tong University and the University of Michigan, where I had a happy time doing mobile network and system research.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1751665705,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://ry4nzhu.github.io/author/ruiyang-zhu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/ruiyang-zhu/","section":"authors","summary":"My name is Ruiyang Zhu. I am a fifth-year Ph.D. student [ CV ] in Computer Science and Engineering at the University of Michigan, advised by Prof. Z. Morley Mao. My research interests broadly include computer systems and networks, with a focus on mobile networks and networked systems.","tags":null,"title":"Ruiyang Zhu","type":"authors"},{"authors":["Ruiyang Zhu","Minkyoung Cho","Shuqing Zeng","Fan Bai","Z. Morley Mao"],"categories":[],"content":"","date":1748570213,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1751247877,"objectID":"16cc5b65bb47aa08904b6a0469668dc5","permalink":"https://ry4nzhu.github.io/publication/scorpion/","publishdate":"2023-05-29T21:56:53-04:00","relpermalink":"/publication/scorpion/","section":"publication","summary":"Collaborative Perception enables multiple agents, such as autonomous vehicles and infrastructure, to share sensor data via vehicular networks so that each agent gains an extended sensing range and better perception quality. Despite its promising benefits, realizing the full potential of such systems faces significant challenges due to inherent imperfections in underlying system layers, consisting of network layer imperfections and hardware-level noises. Such imperfections and noises include packet loss in vehicular networks, localization errors from GPS measurements, and synchronization errors caused by clock deviation and network latency. To address these challenges, we propose a novel end-to-end collaborative perception framework, SCORPION, that harnesses the AI co-design of the application layer and system layer to tackle the aforementioned imperfections. SCORPION consists of three main components: lost bird’s eye view feature reconstruction (L-BEV-R) recovers lost spatial features during lossy V2X communication, while deformable spatial cross attention (DSCA) and temporal alignment (TA) compensate for localization and synchronization errors in feature fusion. Experimental results on both synthetic and real-world collaborative 3D object detection datasets demonstrate that SCORPION advances the state-of-the-art collaborative perception methods by 5.9 - 13.2 absolute AP on both standard and noisy scenarios.","tags":["Autonomous Vehicle","Cooperative Perception"],"title":"SCORPION: Robust Spatial-Temporal Collaborative Perception Model on Lossy Wireless Network","type":"publication"},{"authors":["Ruiyang Zhu*","Minkyoung Cho*","Shuqing Zeng","Fan Bai","Xiang Gao","Z. Morley Mao"],"categories":[],"content":"","date":1748397413,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1751665705,"objectID":"f16032d587e937ce6b29169b7995b686","permalink":"https://ry4nzhu.github.io/publication/scalable_crowded_hd_map_construction/","publishdate":"2023-05-27T21:56:53-04:00","relpermalink":"/publication/scalable_crowded_hd_map_construction/","section":"publication","summary":"High-definition (HD) maps are vital for autonomous driving, providing fine-grained geometric and semantic information beyond the scope of onboard perception. However, automatically constructing accurate vectorized maps at scale using learning-based methods remains challenging, as individual vehicles observe only partial, localized environments. This motivates the need for collaborative HD map construction, where multiple vehicles contribute local observations to build a unified global map. While collaborative perception has been extensively studied through dense BEV fusion, existing methods are fundamentally ego-centric and operate within a fixed perception range, making them ill-suited for large-scale, open-world mapping. In this paper, we propose a graph-based sparse fusion framework for collaborative vectorized HD map construction. Vehicles build local HD maps collaboratively and encode them as sparse geometric graphs, which are fused by a sparse-to-sparse fusion algorithm that incrementally aligns and merges graphs across space and time. This design leverages multi-agent fine-grained features and enables scalable, memory-efficient fusion without relying on dense tensors. Experimental results show that our method constructs accurate global maps under sparse and asynchronous observations, outperforming baselines by over 10.3 mAP.","tags":["Autonomous Vehicle","HD-Map"],"title":"Scalable Crowd-Sourced Global HD Map Construction via Collaborative Map Perception and Sparse Graph Fusion","type":"publication"},{"authors":["Ruiyang Zhu","Xiao Zhu","Anlan Zhang","Xumiao Zhang","Jiachen Sun","Feng Qian","Hang Qiu","Z. Morley Mao","Myungjin Lee"],"categories":[],"content":"","date":1726502213,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1732246062,"objectID":"438025c43a051ceb5aff114b76302e9b","permalink":"https://ry4nzhu.github.io/publication/boosting_collaborative_vehicular_perception_on_the_edge_with_v2v_communication/","publishdate":"2024-09-16T11:56:53-04:00","relpermalink":"/publication/boosting_collaborative_vehicular_perception_on_the_edge_with_v2v_communication/","section":"publication","summary":"","tags":["Autonomous Vehicle","Cooperative Perception"],"title":"Boosting Collaborative Vehicular Perception on the Edge with Vehicle-to-Vehicle Communication","type":"publication"},{"authors":["Qingzhao Zhang","Shuowei Jin","Ruiyang Zhu","Jiachen Sun","Xumiao Zhang","Alfred Chen","Z. Morley Mao"],"categories":[],"content":"","date":1705692293,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1751247599,"objectID":"508c289dbbcd644e3d70a3708b240d84","permalink":"https://ry4nzhu.github.io/publication/on_data_fabircationin_collaborative_vehicular_perception_attacks_and_countermeasures/","publishdate":"2024-01-19T15:24:53-04:00","relpermalink":"/publication/on_data_fabircationin_collaborative_vehicular_perception_attacks_and_countermeasures/","section":"publication","summary":"Collaborative perception, which greatly enhances the sensing capability of connected and autonomous vehicles (CAVs) by incorporating data from external resources, also brings forth potential security risks. CAVs' driving decisions rely on remote untrusted data, making them susceptible to attacks carried out by malicious participants in the collaborative perception system. However, security analysis and countermeasures for such threats are absent. To understand the impact of the vulnerability, we break the ground by proposing various real-time data fabrication attacks in which the attacker delivers crafted malicious data to victims in order to perturb their perception results, leading to hard brakes or increased collision risks. Our attacks demonstrate a high success rate of over 86% on high-fidelity simulated scenarios and are realizable in real-world experiments. To mitigate the vulnerability, we present a systematic anomaly detection approach that enables benign vehicles to jointly reveal malicious fabrication. It detects 91.5% of attacks with a false positive rate of 3% in simulated scenarios and significantly mitigates attack impacts in real-world scenarios.","tags":["Autonomous Vehicle","Cooperative Perception","Security"],"title":"On Data Fabrication in Collaborative Vehicular Perception: Attacks and Countermeasures","type":"publication"},{"authors":["Shuowei Jin","Ruiyang Zhu","Ahmad Hassan","Xiao Zhu","Xumiao Zhang","Z. Morley Mao","Feng Qian","Zhi-Li Zhang"],"categories":[],"content":"","date":1705283813,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1751247599,"objectID":"4036aa6e3c01d0aee0410d8a28098aa3","permalink":"https://ry4nzhu.github.io/publication/oasis/","publishdate":"2024-01-14T21:56:53-04:00","relpermalink":"/publication/oasis/","section":"publication","summary":"Neural-enhanced video streaming (e.g. super-resolution) is an ongoing revolution which can provide extremely high-quality video streaming services breaking the restriction of bandwidth. However, such enhancements require intense computation power that is not affordable for a single mobile device, which hinders their real-world deployment. To address the limitation, we propose OASIS, the first system that facilitates multiple users in close proximity to execute intense neural-enhanced video streaming in real-time. To this end, OASIS intelligently distributes computation tasks among multiple mobile devices, selects appropriate video bitrates and super-resolution models, and optimizes video chunk delivery. As a result, the expensive neural-enhanced streaming is done through distributed collaboration, achieving optimal quality of experience (QoE). We implement and evaluate OASIS on commodity smartphones from different vendors, under various network and computation conditions. Extensive experiments demonstrate the high efficiency of OASIS: it improves the video streaming QoE by 40%-200% and reduces each participant’s energy consumption by 60% when the system scales up from a single device to six devices.","tags":["Neural-enhanced Video Streaming","Mobile Systems"],"title":"OASIS: Collaborative Neural-Enhanced Mobile Video Streaming","type":"publication"},{"authors":["Ahmad Hassan","Anlan Zhang","Wei Ye","Ruiyang Zhu","Shuowei Jin","Jason Carpenter","Z. Morley Mao","Feng Qian","Zhi-Li Zhang"],"categories":[],"content":"","date":1702605413,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1750114456,"objectID":"4a859bebfd0b815e4f51d3be2cf9f6f2","permalink":"https://ry4nzhu.github.io/publication/the_case_for_boosting/","publishdate":"2023-12-14T21:56:53-04:00","relpermalink":"/publication/the_case_for_boosting/","section":"publication","summary":"5G and future 6G networks support diverse combinations of access technologies, architectures, and radio frequencies, with each combination termed as a \"band\" henceforth. Through comprehensive measurements in 12 cities across 5 countries, we experimentally show that operator-configured default bands are often highly suboptimal, particularly under mobility. We then propose smart band switching, where a UE's band can be dynamically changed to improve the network performance and boost the application QoE. We discuss challenges, opportunities, and design choices for building a practical smart band switching system. We further develop preliminary UE-side band-switching logic on commodity smartphones, and evaluate it on commercial 5G networks.","tags":["5G","xG","Band-switching"],"title":"The Case for Boosting Mobile Application QoE via Smart Band Switching in 5G/xG Networks","type":"publication"},{"authors":["Qingzhao Zhang*(co-primary)","Xumiao Zhang*(co-primary)","Ruiyang Zhu*(co-primary)","Fan Bai","Mohammad Naserian","Z. Morley Mao"],"categories":[],"content":"","date":1686794213,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1751247599,"objectID":"9db29cedf9edd8212dbd00260492071f","permalink":"https://ry4nzhu.github.io/publication/robust_real_time/","publishdate":"2023-06-14T21:56:53-04:00","relpermalink":"/publication/robust_real_time/","section":"publication","summary":"Cooperative perception significantly enhances the perception performance of connected autonomous vehicles. Instead of purely relying on local sensors with limited range, it enables multiple vehicles and roadside infrastructures to share sensor data to perceive the environment collaboratively. Through our study, we realize that the performance of cooperative perception systems is limited in real-world deployment due to (1) out-of-sync sensor data during data fusion and (2) inaccurate localization of occluded areas. To address these challenges, we develop RAO, an innovative, effective, and lightweight cooperative perception system that merges asynchronous sensor data from different vehicles through our novel designs of motion-compensated occupancy flow prediction and on-demand data sharing, improving both the accuracy and coverage of the perception system. Our extensive evaluation, including real-world and emulation-based experiments, demonstrates that RAO outperforms state-of-the-art solutions by more than 34% in perception coverage and by up to 14% in perception accuracy, especially when asynchronous sensor data is present. RAO consistently performs well across a wide variety of map topologies and driving scenarios. RAO incurs negligible additional latency (8.5ms) and low data transmission overhead (10.9 KB per frame), making cooperative perception feasible.","tags":["Autonomous Vehicle","Cooperative Perception"],"title":"Robust Real-time Multi-vehicle Collaboration on Asynchronous Sensors","type":"publication"},{"authors":["Ahmad Hassan","Arvind Narayanan","Anlan Zhang","Wei Ye","Ruiyang Zhu","Shuowei Jin","Jason Carpenter","Z. Morley Mao","Zhi-Li Zhang","Feng Qian"],"categories":[],"content":"","date":1653875813,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1751247877,"objectID":"d3f6cfd17af8e30a3e1b2320ef037074","permalink":"https://ry4nzhu.github.io/publication/vivisecting_mobility_management_in_5g/","publishdate":"2022-05-29T21:56:53-04:00","relpermalink":"/publication/vivisecting_mobility_management_in_5g/","section":"publication","summary":"With 5G's support for diverse radio bands and different deployment modes, e.g. standalone (SA) vs. non-standalone (NSA), mobility management - especially the handover process - becomes far more complex. Measurement studies have shown that frequent handovers cause wild fluctuations in 5G throughput, and worst, service outages. Through a cross-country (6,200km+) driving trip, we conduct in-depth measurements to study the current 5G mobility management practices adopted by three major US carriers. Using this rich dataset, we carry out a systematic analysis to uncover the handover mechanisms employed by 5G carriers, and compare them along several dimensions such as (4G vs. 5G) radio technologies, radio (low-, mid- \u0026 high-)bands, and deployment (SA vs NSA) modes. We further quantify the impact of mobility on application performance, power consumption, and signaling overheads. We identify key challenges facing today’s NSA 5G deployments which result in unnecessary handovers and reduced coverage. Finally, we design a holistic handover prediction system Prognos and demonstrate its ability to improve QoE for two 5G applications 16K panoramic VoD and real-time volumetric video streaming. We have released the datasets and tools of our study at https://github.com/SIGCOMM22-5GMobility/artifact.","tags":["5G","mobility management"],"title":" Vivisecting Mobility Management in 5G Cellular Networks","type":"publication"},{"authors":[],"categories":[],"content":"Bugbasev2 is a collection of reproduceable bugs in popular software stsytems (e.g. TensorFlow, MySQL, etc) and their failture sketches. Those reproducible bugs help for evaluating bug detection and root cause diagnosis and is an extension of data for the bugbase project. All the bugs are self-contained inside a docker container and ready to be invoked independently. Currently, the total number of reproducible bugs exceeds 100.\nRelated paper: Failure Sketching: A Technique for Automated Root Cause Diagnosis of In-Production Failures (SOSP'15)\n","date":1619836970,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1656969345,"objectID":"a42c3b0802d4ac9e5da79666ab31784c","permalink":"https://ry4nzhu.github.io/project/bugbasev2/","publishdate":"2021-04-30T22:42:50-04:00","relpermalink":"/project/bugbasev2/","section":"project","summary":"Bugbase (version 2) is a collection of reproduceable bugs in popular software stsytems.","tags":[],"title":"Bugbasev2","type":"project"},{"authors":["Arvind Narayanan*(co-primary)","Xumiao Zhang*(co-primary)","Ruiyang Zhu","Ahmad Hassan","Shuowei Jin","Xiao Zhu","Denis Rybkin","Dustin Zhang","Michael Yang","Z. Morley Mao","Feng Qian","Zhi-Li Zhang"],"categories":[],"content":"","date":1619834213,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1695274112,"objectID":"70adc1f66c7e305600863e72618534f0","permalink":"https://ry4nzhu.github.io/publication/a_variegated_look_at_5g_in_the_wild/","publishdate":"2021-04-30T21:56:53-04:00","relpermalink":"/publication/a_variegated_look_at_5g_in_the_wild/","section":"publication","summary":"Motivated by rapidly expanding deployment of 5G services, we carry out an in-depth study to understand how 5G impacts application performance and energy efficiency. We examine the effects of 5G deployment strategies such as Non-Standalone (NSA) 5G and Standalone (SA), radio bands and protocol specific properties (e.g., RRC state transitions and power profiles) on performance and power usage experienced by user equipment (smart phones) and applications running on them. Unlike previous studies, we focus on both 5G mmWave -- which provides significantly higher throughput than 4G LTE -- and low-band radio (with more comparable throughput with 4G LTE). Our work answers the key questions of how to best utilize 5G for common applications such as video streaming and web browsing, and aid intelligent throughput-power trade-offs.","tags":["5G"],"title":"A Variegated Look at 5G in the Wild: Performance, Power, and QoE Implications","type":"publication"},{"authors":[],"categories":[],"content":"5G has already been deployed in so-called Non-Standalone Deployment (NSA). Vendors such as Verizon, AT\u0026amp;T and T-Mobile adapt the novel milimeter Wave (mmWave) technology to provide extremely high bandwidth and low latency through the celluar network.\n","date":1600115937,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1600227277,"objectID":"1907529056a2cd376f7fd3f48c07c992","permalink":"https://ry4nzhu.github.io/post/5g_radio_resource_control/","publishdate":"2020-09-14T16:38:57-04:00","relpermalink":"/post/5g_radio_resource_control/","section":"post","summary":"5G has already been deployed in so-called Non-Standalone Deployment (NSA). Vendors such as Verizon, AT\u0026amp;T and T-Mobile adapt the novel milimeter Wave (mmWave) technology to provide extremely high bandwidth and low latency through the celluar network.","tags":["5G"],"title":"About 5G NR in General","type":"post"},{"authors":["Ruiyang Zhu","Meitang Li","Tianrong Zhang","Yuan Shen","Kangjia Cai"],"categories":[],"content":"","date":1600100909,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1619838434,"objectID":"526d8c1a4d8216acd866ba77f1358df0","permalink":"https://ry4nzhu.github.io/project/proc_branch_stack/","publishdate":"2020-09-14T12:28:29-04:00","relpermalink":"/project/proc_branch_stack/","section":"project","summary":"We built a two-way superscalar processor with early branch resolution.","tags":["Architecture","RISC-V","SystemVerilog","Out-of-Order","R10K"],"title":"A RISC-V Based Superscalar Out-of-Order Processor Design with Branch Stack","type":"project"},{"authors":null,"categories":null,"content":"Beyond Computer Science, I love watching animes in my spare time. My faviourate anime character is Rem (雷打不动) from Re:Zero and my faviourate voice actress is Nao Touyama.\nIMHO, the top 5 animes that I\u0026rsquo;ve watched are:\n  Hyouka  Yahari Ore no Seishun Love Comedy wa Machigatteiru  Steins;Gate  Re:Zero kara Hajimeru Isekai Seikatsu  3-gatsu no Lion (March comes in like a lion)    3-gatsu no Lion Season 2   ","date":1530144000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614370907,"objectID":"3ef1c3ed755398dc4fffccfec12a9a68","permalink":"https://ry4nzhu.github.io/misc/","publishdate":"2018-06-28T00:00:00Z","relpermalink":"/misc/","section":"","summary":"Hobbies.","tags":null,"title":"MISC info","type":"page"}]